# Image-to-text

This repository contains code for an Image-to-text model using image captioning. The model used in this project is based on Salesforce's Blip Image Captioning Model.

## Description
This project demonstrates how to use the Blip Image Captioning Model to perform conditional and unconditional image captioning and then extract potential keywords based on part-of-speech tagging. The extracted keywords are then matched to predefined categories.

## Prerequisites
Before running the code, make sure you have the following dependencies installed:

Hugging Face Transformers
NLTK (Natural Language Toolkit)

## The steps involved are as follows - 
1. Load libraries
2. Load the Blip Image Captioning Model
3. Upload an image to your suitable environment
4. Perform image to text generation
5. Extract Keywords and Match to Categories
